# Kubernetes éƒ¨ç½²æŒ‡å—

æœ¬ç›®å½•åŒ…å«åœ¨ Kubernetes é›†ç¾¤ä¸­éƒ¨ç½² system-info-exporter çš„æ‰€æœ‰èµ„æºæ–‡ä»¶ã€‚

## ğŸ“ æ–‡ä»¶è¯´æ˜

| æ–‡ä»¶ | è¯´æ˜ |
|-----|------|
| `namespace.yaml` | å‘½åç©ºé—´å®šä¹‰ |
| `configmap.yaml` | åº”ç”¨é…ç½® |
| `daemonset.yaml` | DaemonSet é…ç½®ï¼ˆæ”¯æŒ GPU + CPU æ··åˆèŠ‚ç‚¹ï¼‰ |
| `service.yaml` | Service å®šä¹‰ |
| `servicemonitor.yaml` | Prometheus ServiceMonitorï¼ˆå¯é€‰ï¼‰ |

## ğŸš€ å¿«é€Ÿéƒ¨ç½²

### ä¸€é”®éƒ¨ç½²æ‰€æœ‰èµ„æº

```bash
kubectl apply -f deploy/kubernetes/
```

### åˆ†æ­¥éƒ¨ç½²

```bash
# 1. åˆ›å»ºå‘½åç©ºé—´
kubectl apply -f namespace.yaml

# 2. åˆ›å»ºé…ç½®
kubectl apply -f configmap.yaml

# 3. éƒ¨ç½² DaemonSet
kubectl apply -f daemonset.yaml

# 4. åˆ›å»º Service
kubectl apply -f service.yaml

# 5. å¯é€‰ï¼šå¦‚æœä½¿ç”¨ Prometheus Operator
kubectl apply -f servicemonitor.yaml
```

## ğŸ“‹ å‰ç½®æ¡ä»¶

### GPU èŠ‚ç‚¹è¦æ±‚ï¼ˆå¯é€‰ï¼‰

å¦‚æœé›†ç¾¤ä¸­æœ‰ GPU èŠ‚ç‚¹ï¼š

1. **å®‰è£… NVIDIA é©±åŠ¨**
   ```bash
   # éªŒè¯é©±åŠ¨å®‰è£…
   nvidia-smi
   ```

2. **å®‰è£… NVIDIA Container Toolkit**
   
   éœ€è¦ä»¥ä¸‹ç»„ä»¶ä¹‹ä¸€ï¼š
   - [NVIDIA GPU Operator](https://docs.nvidia.com/datacenter/cloud-native/gpu-operator/overview.html)ï¼ˆæ¨èï¼‰
   - [NVIDIA Device Plugin](https://github.com/NVIDIA/k8s-device-plugin)

### CPU èŠ‚ç‚¹è¦æ±‚

æ— ç‰¹æ®Šè¦æ±‚ï¼Œæ ‡å‡† Kubernetes èŠ‚ç‚¹å³å¯ã€‚

## ğŸ—ï¸ å·¥ä½œåŸç†

### ç»Ÿä¸€ DaemonSet æ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Kubernetes é›†ç¾¤                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                 â”‚
â”‚  GPU èŠ‚ç‚¹                     CPU èŠ‚ç‚¹           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚   Pod          â”‚          â”‚   Pod         â”‚ â”‚
â”‚  â”‚ (auto GPU)     â”‚          â”‚ (CPU only)    â”‚ â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤          â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”‚
â”‚  â”‚ â€¢ GPU æŒ‡æ ‡  âœ… â”‚          â”‚ â€¢ CPU æŒ‡æ ‡ âœ… â”‚ â”‚
â”‚  â”‚ â€¢ CPU æŒ‡æ ‡  âœ… â”‚          â”‚ â€¢ å†…å­˜æŒ‡æ ‡ âœ… â”‚ â”‚
â”‚  â”‚ â€¢ å†…å­˜æŒ‡æ ‡  âœ… â”‚          â”‚               â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚         â”‚                           â”‚          â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚                     â†“                          â”‚
â”‚            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
â”‚            â”‚     Service     â”‚                 â”‚
â”‚            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### æ™ºèƒ½ GPU æ£€æµ‹

1. **GPU èŠ‚ç‚¹**
   - NVIDIA Container Toolkit é€šè¿‡ `NVIDIA_VISIBLE_DEVICES` ç¯å¢ƒå˜é‡è‡ªåŠ¨æ³¨å…¥ GPU æ”¯æŒ
   - ä»£ç æ£€æµ‹åˆ° GPU è®¾å¤‡æ–‡ä»¶ï¼ˆ`/dev/nvidiactl`ã€`/dev/nvidia0` ç­‰ï¼‰
   - åˆå§‹åŒ– NVMLï¼Œé‡‡é›† GPUã€CPUã€å†…å­˜å…¨éƒ¨æŒ‡æ ‡

2. **CPU èŠ‚ç‚¹**
   - æ—  NVIDIA Container Toolkitï¼Œç¯å¢ƒå˜é‡è¢«å¿½ç•¥
   - ä»£ç æ£€æµ‹ä¸åˆ° GPU è®¾å¤‡æ–‡ä»¶
   - è·³è¿‡ GPU åˆå§‹åŒ–ï¼Œåªé‡‡é›† CPU å’Œå†…å­˜æŒ‡æ ‡
   - æ—¥å¿—ï¼š`INFO: No NVIDIA GPU hardware detected, skipping GPU metrics collection`

## ğŸ” éªŒè¯éƒ¨ç½²

### æ£€æŸ¥ Pod çŠ¶æ€

```bash
# æŸ¥çœ‹æ‰€æœ‰ Pod
kubectl get pods -n system-info-exporter -o wide

# åº”è¯¥åœ¨æ‰€æœ‰èŠ‚ç‚¹ä¸Šéƒ½æœ‰ä¸€ä¸ª Pod
```

### æ£€æŸ¥æ—¥å¿—

```bash
# æŸ¥çœ‹ GPU èŠ‚ç‚¹æ—¥å¿—ï¼ˆåº”è¯¥èƒ½çœ‹åˆ° GPU ä¿¡æ¯ï¼‰
kubectl logs -n system-info-exporter <gpu-node-pod-name> --tail=50

# æŸ¥çœ‹ CPU èŠ‚ç‚¹æ—¥å¿—ï¼ˆåº”è¯¥çœ‹åˆ°è·³è¿‡ GPU æ£€æµ‹ï¼‰
kubectl logs -n system-info-exporter <cpu-node-pod-name> --tail=50
```

### æµ‹è¯•æŒ‡æ ‡é‡‡é›†

```bash
# ç«¯å£è½¬å‘
kubectl port-forward -n system-info-exporter svc/system-info-exporter 8080:80

# æµ‹è¯•æŒ‡æ ‡
curl http://localhost:8080/metrics | grep hw_gpu_count
curl http://localhost:8080/metrics | grep hw_cpu_cores
```

## ğŸ“Š é¢„æœŸç»“æœ

### GPU èŠ‚ç‚¹æ—¥å¿—

```json
{"timestamp":"2025-12-12T06:30:00Z","level":"INFO","message":"Starting system-info-exporter"}
{"timestamp":"2025-12-12T06:30:01Z","level":"INFO","message":"Collecting metrics..."}
```

### CPU èŠ‚ç‚¹æ—¥å¿—

```json
{"timestamp":"2025-12-12T06:30:00Z","level":"INFO","message":"Starting system-info-exporter"}
{"timestamp":"2025-12-12T06:30:00Z","level":"INFO","message":"No NVIDIA GPU hardware detected, skipping GPU metrics collection"}
```

### æŒ‡æ ‡ç¤ºä¾‹

#### GPU èŠ‚ç‚¹

```prometheus
hw_gpu_count{node="gpu-node-01"} 8
hw_gpu_memory_total_bytes{node="gpu-node-01",gpu_index="0",...} 85899345920
hw_cpu_cores{node="gpu-node-01"} 48
hw_memory_total_bytes{node="gpu-node-01"} 270582939648
```

#### CPU èŠ‚ç‚¹

```prometheus
hw_gpu_count{node="cpu-node-01"} 0
hw_cpu_cores{node="cpu-node-01"} 16
hw_memory_total_bytes{node="cpu-node-01"} 67108864000
```

## ğŸ”§ é…ç½®è°ƒæ•´

### ä¿®æ”¹èµ„æºé™åˆ¶

ç¼–è¾‘ `daemonset.yaml` ä¸­çš„ `resources` éƒ¨åˆ†ï¼š

```yaml
resources:
  requests:
    cpu: 50m
    memory: 64Mi
  limits:
    cpu: 200m
    memory: 128Mi
```

### ä¿®æ”¹æ—¥å¿—çº§åˆ«

ç¼–è¾‘ `daemonset.yaml` ä¸­çš„ç¯å¢ƒå˜é‡ï¼š

```yaml
env:
  - name: RUST_LOG
    value: "debug"  # å¯é€‰å€¼: error, warn, info, debug, trace
```

### ä¿®æ”¹é‡‡é›†é—´éš”

ç¼–è¾‘ `configmap.yaml` æ–‡ä»¶ï¼š

```yaml
data:
  default.toml: |
    [metrics]
    collect_interval_secs = 15  # é‡‡é›†é—´éš”ï¼ˆç§’ï¼‰
```

## ğŸ”„ æ›´æ–°éƒ¨ç½²

### æ›´æ–°é•œåƒç‰ˆæœ¬

```bash
kubectl set image daemonset/system-info-exporter \
  system-info-exporter=reg.deeproute.ai/deeproute-public/zzh/system-info-exporter:0.1.2 \
  -n system-info-exporter
```

### é‡å¯ Pod

```bash
kubectl rollout restart daemonset/system-info-exporter -n system-info-exporter
```

### æŸ¥çœ‹æ»šåŠ¨æ›´æ–°çŠ¶æ€

```bash
kubectl rollout status daemonset/system-info-exporter -n system-info-exporter
```

## ğŸ—‘ï¸ å¸è½½

```bash
# åˆ é™¤æ‰€æœ‰èµ„æº
kubectl delete -f deploy/kubernetes/

# æˆ–åˆ†æ­¥åˆ é™¤
kubectl delete -f daemonset.yaml
kubectl delete -f service.yaml
kubectl delete -f configmap.yaml
kubectl delete -f namespace.yaml
```

## â“ æ•…éšœæ’æŸ¥

### GPU èŠ‚ç‚¹ä¸Šä»ç„¶æŠ¥é”™ NVML åˆå§‹åŒ–å¤±è´¥

**é—®é¢˜è¯Šæ–­**ï¼š

1. **æ£€æŸ¥ NVIDIA Container Toolkit**
   ```bash
   # åœ¨èŠ‚ç‚¹ä¸Šæ£€æŸ¥
   docker run --rm --gpus all nvidia/cuda:11.0-base nvidia-smi
   ```

2. **æ£€æŸ¥ NVIDIA Device Plugin**
   ```bash
   kubectl get pods -n kube-system | grep nvidia
   ```

3. **æŸ¥çœ‹ Pod è¯¦ç»†ä¿¡æ¯**
   ```bash
   kubectl describe pod -n system-info-exporter <pod-name>
   ```

4. **æŸ¥çœ‹å®¹å™¨æ—¥å¿—**
   ```bash
   kubectl logs -n system-info-exporter <pod-name> --tail=100
   ```

**å¸¸è§åŸå› **ï¼š
- NVIDIA Container Toolkit æœªæ­£ç¡®å®‰è£…æˆ–é…ç½®
- NVIDIA Device Plugin æœªè¿è¡Œ
- Docker/containerd é…ç½®æœªæ›´æ–°

### CPU èŠ‚ç‚¹ä¸Šä¹Ÿåœ¨å°è¯•åˆå§‹åŒ– GPU

**æ£€æŸ¥æ¸…å•**ï¼š

1. ç¡®è®¤ä½¿ç”¨äº†æ–°ç‰ˆæœ¬é•œåƒï¼ˆ0.1.2+ï¼‰
   ```bash
   kubectl get pods -n system-info-exporter -o jsonpath='{.items[*].spec.containers[*].image}'
   ```

2. å¦‚æœç‰ˆæœ¬ä¸å¯¹ï¼Œæ›´æ–° DaemonSet
   ```bash
   kubectl apply -f daemonset.yaml
   kubectl rollout restart daemonset/system-info-exporter -n system-info-exporter
   ```

### Pod æ— æ³•å¯åŠ¨

```bash
# æŸ¥çœ‹ Pod äº‹ä»¶
kubectl describe pod -n system-info-exporter <pod-name>

# æŸ¥çœ‹å‘½åç©ºé—´äº‹ä»¶
kubectl get events -n system-info-exporter --sort-by='.lastTimestamp'

# æŸ¥çœ‹å®¹å™¨æ—¥å¿—
kubectl logs -n system-info-exporter <pod-name>
```

## ğŸ“Š Prometheus é›†æˆ

### éƒ¨ç½² ServiceMonitor

å¦‚æœä½¿ç”¨ Prometheus Operatorï¼š

```bash
kubectl apply -f servicemonitor.yaml
```

### Prometheus æŸ¥è¯¢ç¤ºä¾‹

```promql
# GPU æ•°é‡ï¼ˆæŒ‰èŠ‚ç‚¹ï¼‰
hw_gpu_count

# GPU èŠ‚ç‚¹çš„ GPU æ•°é‡ï¼ˆå¤§äº 0ï¼‰
hw_gpu_count > 0

# CPU ä½¿ç”¨ç‡
hw_cpu_usage_percent{node=~".*"}

# å†…å­˜ä½¿ç”¨ç‡
hw_memory_usage_percent{node=~".*"}

# GPU æ¸©åº¦ï¼ˆä»… GPU èŠ‚ç‚¹ï¼‰
hw_gpu_temperature_celsius

# GPU å†…å­˜ä½¿ç”¨ç‡
100 * hw_gpu_memory_used_bytes / hw_gpu_memory_total_bytes
```

### å‘Šè­¦è§„åˆ™ç¤ºä¾‹

```yaml
groups:
  - name: system-info-exporter
    rules:
      # Exporter ä¸å¯ç”¨
      - alert: SystemInfoExporterDown
        expr: up{job="system-info-exporter"} == 0
        for: 5m
        annotations:
          summary: "System info exporter is down on {{ $labels.node }}"
      
      # GPU èŠ‚ç‚¹ä½†æ—  GPU æŒ‡æ ‡
      - alert: GPUMetricsMissing
        expr: |
          (
            count by (node) (kube_node_labels{label_nvidia_com_gpu_present="true"})
            unless
            count by (node) (hw_gpu_count > 0)
          )
        for: 10m
        annotations:
          summary: "GPU metrics missing on GPU node {{ $labels.node }}"
      
      # GPU æ¸©åº¦è¿‡é«˜
      - alert: GPUHighTemperature
        expr: hw_gpu_temperature_celsius > 85
        for: 10m
        annotations:
          summary: "GPU {{ $labels.gpu_index }} temperature is {{ $value }}Â°C on {{ $labels.node }}"
      
      # GPU å†…å­˜ä½¿ç”¨ç‡è¿‡é«˜
      - alert: GPUMemoryUsageHigh
        expr: |
          (hw_gpu_memory_used_bytes / hw_gpu_memory_total_bytes) * 100 > 90
        for: 15m
        annotations:
          summary: "GPU {{ $labels.gpu_index }} memory usage > 90% on {{ $labels.node }}"
```

## ğŸ” å®‰å…¨è¯´æ˜

- Pod ä»¥é root ç”¨æˆ·è¿è¡Œï¼ˆUID 1000ï¼‰
- ä½¿ç”¨åªè¯»æ ¹æ–‡ä»¶ç³»ç»Ÿ
- ç¦ç”¨æƒé™æå‡
- ç§»é™¤æ‰€æœ‰ Linux capabilities
- åªæŒ‚è½½å¿…è¦çš„å®¿ä¸»æœºæ–‡ä»¶ï¼ˆåªè¯»ï¼‰

## ğŸ“ æ¶æ„ä¼˜åŠ¿

### ç®€åŒ–éƒ¨ç½²
- âœ… å•ä¸€ DaemonSet é…ç½®
- âœ… æ— éœ€æ‰‹åŠ¨æ ‡è®°èŠ‚ç‚¹
- âœ… æ— éœ€é¢å¤–è„šæœ¬
- âœ… è‡ªåŠ¨é€‚é… GPU å’Œ CPU èŠ‚ç‚¹

### æ™ºèƒ½æ£€æµ‹
- âœ… ä»£ç å±‚é¢çš„ GPU ç¡¬ä»¶æ£€æµ‹
- âœ… ä¾èµ– NVIDIA Container Toolkit è‡ªåŠ¨æ³¨å…¥
- âœ… æ— è­¦å‘Šæ—¥å¿—
- âœ… æ¸…æ™°çš„æ—¥å¿—è¾“å‡º

### è¿ç»´å‹å¥½
- âœ… ç»Ÿä¸€ç®¡ç†
- âœ… æ˜“äºæ›´æ–°
- âœ… æ˜“äºç›‘æ§
- âœ… æ˜“äºæ•…éšœæ’æŸ¥

## ğŸ“š å‚è€ƒèµ„æ–™

- [NVIDIA GPU Operator æ–‡æ¡£](https://docs.nvidia.com/datacenter/cloud-native/gpu-operator/overview.html)
- [NVIDIA Container Toolkit](https://github.com/NVIDIA/nvidia-docker)
- [Kubernetes DaemonSet](https://kubernetes.io/docs/concepts/workloads/controllers/daemonset/)

## ğŸ“„ ç‰ˆæœ¬å…¼å®¹æ€§

- Kubernetes: 1.20+
- NVIDIA GPU Operator: 1.9+ï¼ˆå¯é€‰ï¼Œä»… GPU èŠ‚ç‚¹éœ€è¦ï¼‰
- NVIDIA Device Plugin: 0.12+ï¼ˆå¯é€‰ï¼Œä»… GPU èŠ‚ç‚¹éœ€è¦ï¼‰
- Docker/containerd with NVIDIA Container Toolkitï¼ˆå¯é€‰ï¼Œä»… GPU èŠ‚ç‚¹éœ€è¦ï¼‰

## ğŸ†˜ è·å–å¸®åŠ©

å¦‚æœé‡åˆ°é—®é¢˜ï¼š

1. æŸ¥çœ‹ Pod æ—¥å¿—è·å–è¯¦ç»†é”™è¯¯ä¿¡æ¯
2. æ£€æŸ¥èŠ‚ç‚¹ä¸Šçš„ NVIDIA Container Toolkit é…ç½®
3. å‚è€ƒæ•…éšœæ’æŸ¥éƒ¨åˆ†
4. æäº¤ Issue å¹¶é™„ä¸Šè¯¦ç»†æ—¥å¿—

## ğŸ“„ è®¸å¯è¯

MIT
