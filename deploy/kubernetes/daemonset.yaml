apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: system-info-exporter
  namespace: system-info-exporter
  labels:
    app.kubernetes.io/name: system-info-exporter
    app.kubernetes.io/version: "1.0.6"
spec:
  selector:
    matchLabels:
      app.kubernetes.io/name: system-info-exporter
  template:
    metadata:
      labels:
        app.kubernetes.io/name: system-info-exporter
    spec:
      # Use NVIDIA runtime to inject nvidia-smi and libraries
      runtimeClassName: nvidia
      containers:
        - name: system-info-exporter
          image: reg.deeproute.ai/deeproute-public/zzh/system-info-exporter:1.0.6
          imagePullPolicy: IfNotPresent
          ports:
            - name: http
              containerPort: 8080
              protocol: TCP
          env:
            - name: RUST_LOG
              value: "info"
            # NVIDIA environment variables for Container Toolkit
            # Request all GPUs and all capabilities for full NVML access
            - name: NVIDIA_VISIBLE_DEVICES
              value: "all"
            - name: NVIDIA_DRIVER_CAPABILITIES
              value: "all"
            # Use node hostname instead of pod hostname
            - name: NODE_NAME
              valueFrom:
                fieldRef:
                  fieldPath: spec.nodeName
          volumeMounts:
            - name: config
              mountPath: /app/config
              readOnly: true
            - name: host-os-release
              mountPath: /host/etc/os-release
              readOnly: true
            # Mount host's /proc/driver for NVIDIA GPU detection
            - name: host-proc-driver
              mountPath: /host/proc/driver
              readOnly: true
            # Mount nvidia-uvm devices explicitly
            - name: nvidia-uvm
              mountPath: /dev/nvidia-uvm
            - name: nvidia-uvm-tools
              mountPath: /dev/nvidia-uvm-tools
          resources:
            requests:
              cpu: 50m
              memory: 64Mi
            limits:
              cpu: 200m
              memory: 128Mi
          livenessProbe:
            httpGet:
              path: /healthz
              port: http
            initialDelaySeconds: 5
            periodSeconds: 10
            timeoutSeconds: 3
            failureThreshold: 3
          readinessProbe:
            httpGet:
              path: /ready
              port: http
            initialDelaySeconds: 3
            periodSeconds: 5
            timeoutSeconds: 3
            failureThreshold: 3
          securityContext:
            # Need privileged to access GPU devices properly
            privileged: true
            readOnlyRootFilesystem: true
      tolerations:
        # Allow scheduling on GPU nodes
        - key: nvidia.com/gpu
          operator: Exists
          effect: NoSchedule
      volumes:
        - name: config
          configMap:
            name: system-info-exporter-config
        - name: host-os-release
          hostPath:
            path: /etc/os-release
            type: File
        # Mount host's /proc/driver for NVIDIA GPU detection
        - name: host-proc-driver
          hostPath:
            path: /proc/driver
            type: Directory
        # NVIDIA UVM devices for NVML
        - name: nvidia-uvm
          hostPath:
            path: /dev/nvidia-uvm
            type: CharDevice
        - name: nvidia-uvm-tools
          hostPath:
            path: /dev/nvidia-uvm-tools
            type: CharDevice
